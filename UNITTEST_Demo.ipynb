{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe07f3e4-79b6-4c8d-83cf-e58d80a0bd82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a322be4-b287-4762-92c6-05037354e3ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "952ef560-9cff-4919-a256-f30fe1a21313",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create sample dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01c7fc56-cf07-493a-97fd-c6acbaf5e7fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset\n+----------+------------------+----+-----------+\n|CustomerID|              Name| Age|       City|\n+----------+------------------+----+-----------+\n|       001|   Michael Jackson|  30|   New York|\n|       002|        Jane Smith|  40|Los Angeles|\n|       003|         Sam Brown|null|    Chicago|\n|       004|BBohemian Rhapsody|  25|    Houston|\n+----------+------------------+----+-----------+\n\nTransformation_1 dataset\n+----------+------------------+-----+-----------+\n|CustomerID|              Name|  Age|       City|\n+----------+------------------+-----+-----------+\n|       001|   Michael Jackson| 30.0|   New York|\n|       002|        Jane Smith| 40.0|Los Angeles|\n|       003|         Sam Brown|31.67|    Chicago|\n|       004|BBohemian Rhapsody| 25.0|    Houston|\n+----------+------------------+-----+-----------+\n\nTransformation_2 result\nDistinct Customer Count: 4\n"
     ]
    }
   ],
   "source": [
    "# Creating the sample DataFrame\n",
    "data = [\n",
    "    (\"001\", \"Michael Jackson\", 30, \"New York\"),\n",
    "    (\"002\", \"Jane Smith\", 40, \"Los Angeles\"),\n",
    "    (\"003\", \"Sam Brown\", None, \"Chicago\"),\n",
    "    (\"004\", \"BBohemian Rhapsody\", 25, \"Houston\")\n",
    "]\n",
    "schema = [\"CustomerID\", \"Name\", \"Age\", \"City\"]\n",
    "df = spark.createDataFrame(data, schema)\n",
    "print(\"original dataset\")\n",
    "df.show()\n",
    "\n",
    "# Applying the business logic transformations\n",
    "# Transformation_1: Replace null values in 'Age' with the average 'Age'\n",
    "average_age = df.select(avg(col(\"Age\"))).first()[0]\n",
    "df = df.withColumn(\"Age\", when(col(\"Age\").isNull(), lit(average_age)).otherwise(col(\"Age\")))\n",
    "df = df.withColumn(\"Age\", round(col(\"Age\"), 2))\n",
    "print(\"Transformation_1 dataset\")\n",
    "df.show()\n",
    "\n",
    "# Transformation_2: Count the distinct total number of customers\n",
    "df_count = df.select('CustomerID').distinct().count()\n",
    "print(\"Transformation_2 result\")\n",
    "print(f\"Distinct Customer Count: {df_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a5f5dc4-75c7-4876-abb1-96cd0b0ab93b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Unit Test class\n",
    "class TestCustomerTransformation(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        \"\"\"\n",
    "        Set up the test by reading the data into a DataFrame.\n",
    "        \"\"\"\n",
    "        warnings.filterwarnings(\"ignore\", category=ResourceWarning)\n",
    "        \n",
    "        # Use the existing Spark session instead of creating a new one\n",
    "        self.spark = spark\n",
    "\n",
    "    def test_null_age_values(self):\n",
    "        \"\"\"\n",
    "        Test the Age transformation applied on the dataframe.\n",
    "        \"\"\"\n",
    "        # Count null values in Age column\n",
    "        age_null_count = df.filter(col('Age').isNull()).count()\n",
    "        self.assertEqual(age_null_count, 0, \n",
    "                         f\"Error: The Age_Null_count obtained after transformation is {age_null_count} (should be 0).\")\n",
    "\n",
    "    def test_distinct_customer_count(self):\n",
    "        \"\"\"\n",
    "        Test to check the number of distinct customers.\n",
    "        \"\"\"\n",
    "        distinct_records = df.select('CustomerID').distinct().count()\n",
    "        expected_records = 5  \n",
    "        self.assertEqual(distinct_records, expected_records, \n",
    "                         f\"The total records in the register is {distinct_records}, which is not the expected count of {expected_records}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e2ec471-a94d-4954-9f8c-15559ee8c4fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "======================================================================\nFAIL: test_distinct_customer_count (__main__.TestCustomerTransformation)\nTest to check the number of distinct customers.\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \"<command-4325684114186129>\", line 28, in test_distinct_customer_count\n    self.assertEqual(distinct_records, expected_records,\nAssertionError: 4 != 5 : The total records in the register is 4, which is not the expected count of 5.\n\n----------------------------------------------------------------------\nRan 2 tests in 0.826s\n\nFAILED (failures=1)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\nSummary:\n\nFailing tests:\n - test_distinct_customer_count (__main__.TestCustomerTransformation)\n"
     ]
    }
   ],
   "source": [
    "# Custom Test Result class to track passing tests\n",
    "class CustomTestResult(unittest.TextTestResult):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.passing_tests = []\n",
    "\n",
    "    def addSuccess(self, test):\n",
    "        super().addSuccess(test)\n",
    "        self.passing_tests.append(test)  # Track passing tests\n",
    "\n",
    "def run_tests_1():\n",
    "    \"\"\"\n",
    "    Function to run the unittest test cases manually, displaying only passing and failing tests.\n",
    "    \"\"\"\n",
    "    suite = unittest.TestLoader().loadTestsFromTestCase(TestCustomerTransformation)\n",
    "    combined_suite = unittest.TestSuite(suite)\n",
    "    \n",
    "    # Run the combined test suite with a custom runner\n",
    "    runner = unittest.TextTestRunner(resultclass=CustomTestResult, verbosity=0)\n",
    "    result = runner.run(combined_suite)\n",
    "    \n",
    "    # Display summary of passing and failing tests\n",
    "    print(\"\\nSummary:\")\n",
    "\n",
    "    print(\"\\nFailing tests:\")\n",
    "    if result.failures or result.errors:\n",
    "        for failed_test, _ in result.failures + result.errors:  # Only print the test names, not tracebacks\n",
    "            print(f\" - {failed_test}\")\n",
    "    else:\n",
    "        print(\"No failed tests found\")\n",
    "\n",
    "# Run the tests manually\n",
    "run_tests_1()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "UNITTEST_Demo",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
